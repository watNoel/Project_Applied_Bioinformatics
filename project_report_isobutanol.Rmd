---
title: 'Reproduction of Critical Roles of the PPP and GLN3 in Isobutanol-specific Tolerance in Yeast'
  output: pdf_document:
    df_print: paged
---

We are aiming to reproduce the RNA-seq data processing of the paper 'Reproduction of Critical Roles of the Pentose Phosphate Pathways and GLN3 in Isotbutanol-specific Tolerance in Yeast'. For this, we got access to the raw data provided by the authors in ArrayExpress (link to the data here: https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-8175/samples/?keywords=&organism=Saccharomyces%20cerevisiae&exptype[0]=%22rna%20assay%22&exptype[1]=%22sequencing%20assay%22&array=&fbclid=IwAR3dXafs8wJy6KvOuBFWZ_VjdcdRLObAOHYBvS93zaXq3j9b1Xw60g4154M). 

We extracted the FASTq files following the instructions provided by Filip on Canvas. 

```{}
wget https://www.ebi.ac.uk/arrayexpress/files/E-MTAB-8175/E-MTAB-8175.sdrf.txt

less -S E-MTAB-8175.sdrf.txt

cat E-MTAB-8175.sdrf.txt | cut -f35 | tail -n +2 > links2download.txt #extracting the links to download the FASTq files
wget -N -i links2download.txt #download FASTq files 
 
```

As a result we obtained 16 FASTq files corresponding to our different samples. 

To understand better the context of the data, the samples are divided in wild-type (WT) strains and GLN3âˆ† (gln3) strains. For each genotype, we get two samples growing in normal conditions (add here information about "normal conditions" from the paper) and two samples growing in 1,3% v/v isobutanol. The RNA-seq experiment was duplicated for each of the samples, meaning that from 2 different cultures grown at same conditions we get 4 duplicates. 

We will also use the reference genome of S. cerevisiae to map our reads further on. To feth the reference genome, we went to the Sacharomyces Genome Database and download the same reference genome that they used for their experiment: S288C_reference_genome_R64-1-1-20110203

```{}
wget https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/S288C_reference_genome_R64-1-1_20110203.tgz
tar -xvzf S288C_reference_genome_R64-1-1_20110203.tgz #to decompress the file

```

We will start by trying to align the reads to the reference genome that we downloaded. The alignment is made using TopHats. TopHats we will map the reads to the gene reference genome using the tool bowtie. However, to use the reference genome TopHats need an index for the reference genome. Therefore, we will first create this index by using bowtie2-build. 

```{}
bowtie2-build -f S288C_reference_sequence_R64-1-1_20110203.fsa bowtie_index/reference_genome
```

We aligned the RNA-seq to the the S288C reference genome using tophat (version 2.0.13).  Using the following command: 

```{}
tophat -o alignment/dgln31 /reference_genome/bowtie_index/S288C raw_data/fasta_file_names/dgln31_1.fastq.gz raw_data/fasta_file_names/dgln31_2.fastq.gz
```

Tophat is an alignment tool based on Bowtie that maps reads against a reference genome (provided as an argument in the command, in the form of index files created by bowtie in the previous step). In our case, we are giving the command pair-end reads that were produced in Illumina. 

We get an output composed of several files, including an align summary that indicates we got a 92.4% concordant pair alignment rate.
A concordanr pait alignment rate means that the reads provided are correct (read_1 in forward direction and read_2 in reverse) and that they have an insert size of 500bp.
This is a high percentage, which is good because anything not included in a corcondant pair will not be used in further downstream analysis (which would mean that with a low rate here we would be loosing a lot of information in the analysis). We get a high number of multiple alignments (77.9%) which is quite a high number. An explanation for this might be that our reads are too short to have a unique alignment. Some multiple alignment is expected because a genome contains repeated regions and pseudogenes. Maybe it is also a consequence of not having performed any quality check on the data before the alignment.  

Now, we need to sort our alignment. For this we are going to use samtools, which has a 'sort' command that sorts alignments by lefmost coordinates.

```{}
samtools sort accepted_hits.bam -o accepted_hits.sorted.bam
```


We tried here to use the option -g and provide it with the annotation file .gff but we experienced some problems that we think are because our reference genome is from 2011 (since we are using the one they used for the paper) and the version of TopHats is recent and probably cannot manage the format of our .gff file. We decided to carry on because we should be able to incorporate the same information later on using Cufflinks. 

We use "samtools sort" to sort the bam file before using PicardTools. Sorting will simply make PicardTools work faster. 
```{}
samtools sort dgln32/accepted_hits.bam -o dgln32/accepted_hits.sorted.bam
```

We use now PicardTools to remove the PCR duplicates. 
```{}
picard MarkDuplicates REMOVE_DUPLICATE=True I=accepted_hits.sorted.bam O= marked_duplicates_removed.bam M= marked_dup_metrics_removed.txt
```
We removed the duplicates as indicated in the paper. However, it is important to consider that it is hard to be sure that this duplicates were all artificial (PCR or optical duplicates) and not a natural consequence of the high coverage of the sequencing experiment. 

After removal of duplicates, the next step was to run cufflinks commands on all files to further step into using cuffmerge to get a combined gtf file.

We ran cufflinks in the folder named for the particular replicate and condition, e.g dgl31  as follows:

```{}
cufflinks -g <path-to-reference>.gff sorted_marked_duplicates_removed.bam -o cufflinks_output"
```
This was run for all four files with the gene deletion strain. Thus, the output of this, cufflinks_output, became a new directory within the folder named after the sample. e.g it was stored in 
data/alignmnets/dgln31/cufflinks_output. note that some of these direcotried are named cufflinks_result and not cufflinks_output

The next thing to do was run cuffmerge to get a reference gtf.file for cuffdiff to use. 
for this, i created a new directory called cuffmerge_work in the data directory. There i created a file of all the paths to the assembled genomes transcript.gtf files, meaning the output of cufflinks.

i then ran this command to perform cuffmerges and produece a common gtffile.
```{}
cuffmerge -o cuffmerge_out_gln3 -g ~/Project/data/S288C_reference_genome_R64-1-1_20110203/*.gff -s ~/Project/data/S288C_reference_genome_R64-1-1_20110203/S288C_reference_sequence_R64-1-1_20110203.fsa assemblies.txt
```
Note that the program crashed almost immediately, saying that it couldnt find chromosomes in the fasta files and also gave warnings about not-found bam-files. this is strange since we supplied the same reference fsa file as we have used all the time and no bam file was rewuired for the program to run. 
Nevertheless, a new gtf file called "merged.gtf" was produced by cuffmerge, and we decided to move onward with that file!

The next step was to somehow create a maskfile in gtf file format which contained information about tRNA, rRNA and non-coding RNA transcripts found in the assembly, which should be ignored during differential expression analysis.
Since there seemed to be no possible way of obtaining such a file from the internet, no more one in the same gtf format as the merged.gtf, we figured we should somehow identify from the original gff file with the gene annotation which transcripts and their locations in the genome should be ignored. We did this in the command line using grep and sed.
The idea was: extract all IDs of the undesired transcripts from the reference genome. then query the merged.gtf file for these transcript IDs and create a file with all the lines of the gtf file which has these ids in it. These should then be ignored, i.e be called a maskfile in the cuffdiff program!

```{}
sed 's/;.*//' saccharomyces_cerevisiae_R64-1-1_20110208.gff | cut -f 3,9 | grep -e 'tRNA' -e 'rRNA' -e 'snoRNA' > masking_indices
sed 's/[^=]*=//' masking_indices > only_IDS
grep --file=only_IDS merged.gtf > mask_gln3.gtf 
```  
In this fashion, we got a mask_gln3.gtf file with al undersired alignments! took about 4 hours to come up with for 2 people....

Next step was to run cuffdiff with all these files and assembled bam.files from tophat!

We did this in again a new direcotry called cuffdiff_work where the relevant merge.gtf file along with maskfiles and all bam.files were copied to!
The cuffdiff command we used was this
```{}
cuffdiff -M mask_gln3.gtf -b ../../data/S288C_reference_genome_R64-1-1_20110203/S288C_reference_sequence_R64-1-1_20110203.fsa -o diff_out_dgln3 -u merged.gtf -L C0,C13 dgln31_accepted_hits.bam,dgln32_accepted_hits.bam dgln3_isobutanol_1_accepted_hits.bam,dgln3_isobutanol_2_accepted_hits.bam 
```
Note that the output diff_out_dgln3 was very strange. All Fpkmvalues reported were zero corresponding to all the gene-ids from the reference genome. and cuffdiff did throw an error relating to the fsa-file, something about no chromosome found etc...

Therefore, the next step is to try with another reference genome gtf to see if that works. ALso, the whole pipeline has to be run for the wildtype strain!









APPENDIX
List of programs and versions used and commands used to install it 

we enter environment by "source activate student8"
installed into conda enveronment tophat version 2.0.13
as " conda install -c bioconda tophat=2.0.13 
installed cufflinks as "conda install cufflinks", this should include cuffdiff
it seems conda install -c bioconda cufflinks does the same thing,
installed picard as conda install -c bioconda picard=1.126


